{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"A \"Chatable\" Study Database \ud83d\udcac \u00b6 Data in practice, manually collected data and this is a repository for modeling Kevin's study time in UCSD starting from 2022 as a Freshman. Data changes format through out different quarters, becoming more developed and suitable, so merging and some cleaning is needed at first. Each quarter's data includes one data frame of all the study/work time data and an text feature data frame for the work conducted: One almost fully Timestamp + Numerical data frame ( year_quarter_study ) that records all the study_time One almost fully Timestamp + Text data frame ( year_quarter_text ) that records the precise study_subject Data currently include: 2022_fall_study.csv + 2022_fall_text.csv 2022_winter_study.csv + 2022_winter_text.csv 2022_spring_study.csv + 2022_spring_text.csv 2022_summer_study.csv + 2022_summer_text.csv 2023_fall_study.csv + 2023_fall_text.csv 2024_winter_study.csv + 2024_winter_text.csv 2024_spring_study.csv + 2024_spring_text.csv 2024_summer_study.csv + 2024_summer_text.csv 2024_fall_study.csv + 2024_fall_text.csv Currently I did: Created a chating function where an language model would take all the text in the csv files as embedding and build a personalized search engine. Conducted explorative data analysis with numerical data, specifcally timestamp data.","title":"Study Database"},{"location":"#a-chatable-study-database","text":"Data in practice, manually collected data and this is a repository for modeling Kevin's study time in UCSD starting from 2022 as a Freshman. Data changes format through out different quarters, becoming more developed and suitable, so merging and some cleaning is needed at first. Each quarter's data includes one data frame of all the study/work time data and an text feature data frame for the work conducted: One almost fully Timestamp + Numerical data frame ( year_quarter_study ) that records all the study_time One almost fully Timestamp + Text data frame ( year_quarter_text ) that records the precise study_subject Data currently include: 2022_fall_study.csv + 2022_fall_text.csv 2022_winter_study.csv + 2022_winter_text.csv 2022_spring_study.csv + 2022_spring_text.csv 2022_summer_study.csv + 2022_summer_text.csv 2023_fall_study.csv + 2023_fall_text.csv 2024_winter_study.csv + 2024_winter_text.csv 2024_spring_study.csv + 2024_spring_text.csv 2024_summer_study.csv + 2024_summer_text.csv 2024_fall_study.csv + 2024_fall_text.csv Currently I did: Created a chating function where an language model would take all the text in the csv files as embedding and build a personalized search engine. Conducted explorative data analysis with numerical data, specifcally timestamp data.","title":"A \"Chatable\" Study Database \ud83d\udcac"},{"location":"api/","text":"Setting Up & Running \"Chat\" Function on Database \u00b6 Create the conda enviornment by: conda env create If you want to use GPT with API, you need to create your own OpenAI account and then embed your API key in your system with writing this in your .bash file: export OPENAI_API_KEY = \"your api key\" Run the following to update system file: source ~/. bash_profile Enter the conda environment conda activate ucsd_study Then run an instance ( chat_with_feedback ) of our chat function by: python chat / chat_with_feedback . py We have created a few versions of our chat functions: - chat_base.py is the vanill implementation of the chat function. - chat_langchain.py atampts to us the langchain package ( not working yet ). - chat_standard.py is the currently useful standard version. - chat_with_feedcack.py is chat_standard.py but implemented a feedcak for follow up questions, which is much smarter and useful than the standard version. An example of chat feedback in in here and we have a demo of chat function in here: Your browser does not support the video tag.","title":"API Calls"},{"location":"api/#setting-up-running-chat-function-on-database","text":"Create the conda enviornment by: conda env create If you want to use GPT with API, you need to create your own OpenAI account and then embed your API key in your system with writing this in your .bash file: export OPENAI_API_KEY = \"your api key\" Run the following to update system file: source ~/. bash_profile Enter the conda environment conda activate ucsd_study Then run an instance ( chat_with_feedback ) of our chat function by: python chat / chat_with_feedback . py We have created a few versions of our chat functions: - chat_base.py is the vanill implementation of the chat function. - chat_langchain.py atampts to us the langchain package ( not working yet ). - chat_standard.py is the currently useful standard version. - chat_with_feedcack.py is chat_standard.py but implemented a feedcak for follow up questions, which is much smarter and useful than the standard version. An example of chat feedback in in here and we have a demo of chat function in here: Your browser does not support the video tag.","title":"Setting Up &amp; Running \"Chat\" Function on Database"},{"location":"eda/","text":"Conducting explorative analysis on the numerical data. Mainly focuses on looking at changes in study habits reflected in study times. Temporal Analysis: \u00b6 Looking at some overall temporal trend and how study hours flunctuate in different week days, different quarters, and different years. Looks like study time overall increases. We can also look at some specific categories of what I do, specifcally speaking ( research , dsc , math , and cogs ), we cna spot some category specific trend. We can also examine how study hours changes as a function of week days , week number , and year . We can also look at season's effect on study times by a heatmap againwhere we can see that there is an overall increase in study time over the year and the most study time at Fall and Spring quarter. Dimensionality Reductions \u00b6 Doing some dimensionality reduction technique to show some underlaying property of each quarter being different, specifcally showing different study habits. Categorical Course Analysis \u00b6 Created an overall statistics of how each course varies on time usage, having details relative to each classes.","title":"EDA"},{"location":"eda/#temporal-analysis","text":"Looking at some overall temporal trend and how study hours flunctuate in different week days, different quarters, and different years. Looks like study time overall increases. We can also look at some specific categories of what I do, specifcally speaking ( research , dsc , math , and cogs ), we cna spot some category specific trend. We can also examine how study hours changes as a function of week days , week number , and year . We can also look at season's effect on study times by a heatmap againwhere we can see that there is an overall increase in study time over the year and the most study time at Fall and Spring quarter.","title":"Temporal Analysis:"},{"location":"eda/#dimensionality-reductions","text":"Doing some dimensionality reduction technique to show some underlaying property of each quarter being different, specifcally showing different study habits.","title":"Dimensionality Reductions"},{"location":"eda/#categorical-course-analysis","text":"Created an overall statistics of how each course varies on time usage, having details relative to each classes.","title":"Categorical Course Analysis"}]}