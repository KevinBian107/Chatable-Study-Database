{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"A \"Chatable\" Study Database \ud83d\udcac \u00b6 Data in practice, manually collected data and this is a repository for modeling Kevin's study time in UCSD starting from 2022 as a Freshman. Data changes format through out different quarters, becoming more developed and suitable, so merging and some cleaning is needed at first. Each quarter's data includes one data frame of all the study/work time data and an text feature data frame for the work conducted: One almost fully Timestamp + Numerical data frame ( year_quarter_study ) that records all the study_time One almost fully Timestamp + Text data frame ( year_quarter_text ) that records the precise study_subject Data currently include: 2022_fall_study.csv + 2022_fall_text.csv 2022_winter_study.csv + 2022_winter_text.csv 2022_spring_study.csv + 2022_spring_text.csv 2022_summer_study.csv + 2022_summer_text.csv 2023_fall_study.csv + 2023_fall_text.csv 2024_winter_study.csv + 2024_winter_text.csv 2024_spring_study.csv + 2024_spring_text.csv 2024_summer_study.csv + 2024_summer_text.csv 2024_fall_study.csv + 2024_fall_text.csv Currently I did: Created a chating function where an language model would take all the text in the csv files as embedding and build a personalized search engine. Conducted explorative data analysis with numerical data, specifcally timestamp data.","title":"Why?"},{"location":"#a-chatable-study-database","text":"Data in practice, manually collected data and this is a repository for modeling Kevin's study time in UCSD starting from 2022 as a Freshman. Data changes format through out different quarters, becoming more developed and suitable, so merging and some cleaning is needed at first. Each quarter's data includes one data frame of all the study/work time data and an text feature data frame for the work conducted: One almost fully Timestamp + Numerical data frame ( year_quarter_study ) that records all the study_time One almost fully Timestamp + Text data frame ( year_quarter_text ) that records the precise study_subject Data currently include: 2022_fall_study.csv + 2022_fall_text.csv 2022_winter_study.csv + 2022_winter_text.csv 2022_spring_study.csv + 2022_spring_text.csv 2022_summer_study.csv + 2022_summer_text.csv 2023_fall_study.csv + 2023_fall_text.csv 2024_winter_study.csv + 2024_winter_text.csv 2024_spring_study.csv + 2024_spring_text.csv 2024_summer_study.csv + 2024_summer_text.csv 2024_fall_study.csv + 2024_fall_text.csv Currently I did: Created a chating function where an language model would take all the text in the csv files as embedding and build a personalized search engine. Conducted explorative data analysis with numerical data, specifcally timestamp data.","title":"A \"Chatable\" Study Database \ud83d\udcac"},{"location":"api/","text":"Setting Up & Running \"Chat\" Function on Database \u00b6 Create the conda enviornment by: conda env create If you want to use GPT with API, you need to create your own OpenAI account and then embed your API key in your system with writing this in your .bash file: export OPENAI_API_KEY = \"your api key\" Run the following to update system file: source ~/. bash_profile Enter the conda environment conda activate ucsd_study Then run an instance ( chat_with_feedback ) of our chat function by: python chat / chat_with_feedback . py We have created a few versions of our chat functions: - chat_base.py is the vanill implementation of the chat function. - chat_langchain.py atampts to us the langchain package ( not working yet ). - chat_standard.py is the currently useful standard version. - chat_with_feedcack.py is chat_standard.py but implemented a feedcak for follow up questions, which is much smarter and useful than the standard version. An example of chat feedback in in here Demos of chat function: Your browser does not support the video tag.","title":"API Calls"},{"location":"api/#setting-up-running-chat-function-on-database","text":"Create the conda enviornment by: conda env create If you want to use GPT with API, you need to create your own OpenAI account and then embed your API key in your system with writing this in your .bash file: export OPENAI_API_KEY = \"your api key\" Run the following to update system file: source ~/. bash_profile Enter the conda environment conda activate ucsd_study Then run an instance ( chat_with_feedback ) of our chat function by: python chat / chat_with_feedback . py We have created a few versions of our chat functions: - chat_base.py is the vanill implementation of the chat function. - chat_langchain.py atampts to us the langchain package ( not working yet ). - chat_standard.py is the currently useful standard version. - chat_with_feedcack.py is chat_standard.py but implemented a feedcak for follow up questions, which is much smarter and useful than the standard version. An example of chat feedback in in here Demos of chat function: Your browser does not support the video tag.","title":"Setting Up &amp; Running \"Chat\" Function on Database"},{"location":"eda/","text":"Explorative Data Analysis \u00b6 Conducting explorative analysis on the numerical data. Mainly focuses on looking at changes in study habits reflected in study times. Temporal Analysis: \u00b6 Overall temporal trend and how study hours flunctuate in different week days, quarters, and years. Dimensionality Reductions \u00b6 Showing some underlaying property of each quarter being different, showing different study habits. Categorical Analysis \u00b6 Statistics of how each course varies on time usage.","title":"EDA"},{"location":"eda/#explorative-data-analysis","text":"Conducting explorative analysis on the numerical data. Mainly focuses on looking at changes in study habits reflected in study times.","title":"Explorative Data Analysis"},{"location":"eda/#temporal-analysis","text":"Overall temporal trend and how study hours flunctuate in different week days, quarters, and years.","title":"Temporal Analysis:"},{"location":"eda/#dimensionality-reductions","text":"Showing some underlaying property of each quarter being different, showing different study habits.","title":"Dimensionality Reductions"},{"location":"eda/#categorical-analysis","text":"Statistics of how each course varies on time usage.","title":"Categorical Analysis"}]}