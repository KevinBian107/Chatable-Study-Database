{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textual Analysis\n",
    "You should create an seperate `yaml` for each of the project you are working on, this is a good practice in general. Thesre migt be weird issues that causes a dependency problem. For the same reason a new `yaml` file would record all the dependencies that would ensure this pipeline works for future references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/kevinb/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.keys()\n",
    "pio.renderers.default = 'notebook' \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from utils.eda import *\n",
    "from utils.text_model import transform_text, tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text data\n",
    "fall_2022_text = pd.read_csv('data/2022_fall_text.csv')\n",
    "winter_2023_text = pd.read_csv('data/2023_winter_text.csv')\n",
    "spring_2023_text = pd.read_csv('data/2023_spring_text.csv')\n",
    "summer_2023_text = pd.read_csv('data/2023_summer_text.csv')\n",
    "fall_2023_text = pd.read_csv('data/2023_fall_text.csv')\n",
    "winter_2024_text = pd.read_csv('data/2024_winter_text.csv')\n",
    "spring_2024_text = pd.read_csv('data/2024_spring_text.csv')\n",
    "summer_2024_text = pd.read_csv('data/2024_summer_text.csv')\n",
    "fall_2024_text = pd.read_csv('data/2024_fall_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Study Materials</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022Q1</td>\n",
       "      <td>2022-02-14 | 2022Q1 | Book read (30m), DOC 2 P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022Q1</td>\n",
       "      <td>2022-02-15 | 2022Q1 | Nutrition read (15m), Ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022Q4 | 2022Q4</td>\n",
       "      <td>2022-10-21 | 2022Q4 | 2022Q4 |</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022Q4 | 2022Q4</td>\n",
       "      <td>2022-10-22 | 2022Q4 | 2022Q4 | After consecuti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022Q4 | 2022Q4 | 2022Q4 | 2022Q4 | 2022Q4</td>\n",
       "      <td>2022-10-23 | 2022Q4 | 2022Q4 | 2022Q4 | 2022Q4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>2024Q4</td>\n",
       "      <td>2024-12-11 | 2024Q4 | RPLH eval + paper algori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>2024Q4</td>\n",
       "      <td>2024-12-12 | 2024Q4 | track-mjx meeting, RPLH ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>2024Q4</td>\n",
       "      <td>2024-12-13 | 2024Q4 | constraint article, EM a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>2024Q4</td>\n",
       "      <td>2024-12-14 | 2024Q4 | chill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>2024Q4</td>\n",
       "      <td>2024-12-15 | 2024Q4 | training, rplh summary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>633 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Quarter  \\\n",
       "0                                        2022Q1   \n",
       "1                                        2022Q1   \n",
       "2                               2022Q4 | 2022Q4   \n",
       "3                               2022Q4 | 2022Q4   \n",
       "4    2022Q4 | 2022Q4 | 2022Q4 | 2022Q4 | 2022Q4   \n",
       "..                                          ...   \n",
       "628                                      2024Q4   \n",
       "629                                      2024Q4   \n",
       "630                                      2024Q4   \n",
       "631                                      2024Q4   \n",
       "632                                      2024Q4   \n",
       "\n",
       "                                       Study Materials  \n",
       "0    2022-02-14 | 2022Q1 | Book read (30m), DOC 2 P...  \n",
       "1    2022-02-15 | 2022Q1 | Nutrition read (15m), Ph...  \n",
       "2                      2022-10-21 | 2022Q4 | 2022Q4 |   \n",
       "3    2022-10-22 | 2022Q4 | 2022Q4 | After consecuti...  \n",
       "4    2022-10-23 | 2022Q4 | 2022Q4 | 2022Q4 | 2022Q4...  \n",
       "..                                                 ...  \n",
       "628  2024-12-11 | 2024Q4 | RPLH eval + paper algori...  \n",
       "629  2024-12-12 | 2024Q4 | track-mjx meeting, RPLH ...  \n",
       "630  2024-12-13 | 2024Q4 | constraint article, EM a...  \n",
       "631                        2024-12-14 | 2024Q4 | chill  \n",
       "632       2024-12-15 | 2024Q4 | training, rplh summary  \n",
       "\n",
       "[633 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial Concat\n",
    "text = pd.concat([fall_2022_text, winter_2023_text, spring_2023_text, summer_2023_text, fall_2023_text, winter_2024_text, spring_2024_text, summer_2024_text, fall_2024_text], axis=0)\n",
    "clean_text = text.pipe(transform_text)\n",
    "clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17285"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_process = (clean_text['Study Materials']\n",
    "              .str.lower()\n",
    "              .str.replace(r'\\([\\d]*m\\)','',regex=True)\n",
    "              .str.replace(',','')\n",
    "              .str.strip())\n",
    "\n",
    "corpus = ' '.join(pre_process.astype(str).to_list())\n",
    "tokens = nltk.tokenize.word_tokenize(corpus, language='english')\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Chat Familier With My Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using either of `sentence-transformer`, `nltk`, `openai`, `langchain`, or related stuff has many dependency issue if just pyt in a big environment, need to have a seperated contained environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/kevinb/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import ast\n",
    "import openai\n",
    "import os\n",
    "\n",
    "nltk.download('punkt')\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks created: 633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 20/20 [00:00<00:00, 37.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to embeddings.csv\n"
     ]
    }
   ],
   "source": [
    "from utils.text_model import split_text_nltk, get_similar_chunks, generate_response\n",
    "\n",
    "documents = clean_text['Study Materials'].tolist()\n",
    "all_chunks = []\n",
    "for doc in documents:\n",
    "    chunks = split_text_nltk(doc)\n",
    "    all_chunks.extend(chunks)\n",
    "\n",
    "print(f\"Total chunks created: {len(all_chunks)}\")\n",
    "embeddings = model.encode(all_chunks, show_progress_bar=True, convert_to_tensor=False)\n",
    "\n",
    "embedding_df = pd.DataFrame({\n",
    "    'chunk': all_chunks,\n",
    "    'embedding': embeddings.tolist(),\n",
    "    'quarter': clean_text['Quarter']\n",
    "})\n",
    "\n",
    "embedding_df.to_csv('embeddings.csv', index=False)\n",
    "print(\"Embeddings saved to embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index has 633 vectors.\n"
     ]
    }
   ],
   "source": [
    "embedding_df = pd.read_csv('embeddings.csv')\n",
    "embedding_df['embedding'] = embedding_df['embedding'].apply(ast.literal_eval)\n",
    "\n",
    "# Convert embeddings to a NumPy array of type float32\n",
    "embeddings = np.array(embedding_df['embedding'].tolist()).astype('float32')\n",
    "\n",
    "# Initialize FAISS index and using L2 distance, can also use cosine similarity\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "# Add embeddings to the index\n",
    "index.add(embeddings)\n",
    "print(f\"FAISS index has {index.ntotal} vectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk</th>\n",
       "      <th>embedding</th>\n",
       "      <th>quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-02-14 | 2022Q1 | Book read (30m), DOC 2 P...</td>\n",
       "      <td>[-0.03888290748000145, 0.00010052329889731482,...</td>\n",
       "      <td>2022Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-02-15 | 2022Q1 | Nutrition read (15m), Ph...</td>\n",
       "      <td>[-0.07007762789726257, -0.05126873403787613, 0...</td>\n",
       "      <td>2022Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10-21 | 2022Q4 | 2022Q4 |</td>\n",
       "      <td>[-0.04180379584431648, 0.03743821382522583, 0....</td>\n",
       "      <td>2022Q4 | 2022Q4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-10-22 | 2022Q4 | 2022Q4 | After consecuti...</td>\n",
       "      <td>[-0.06285377591848373, -0.010527550242841244, ...</td>\n",
       "      <td>2022Q4 | 2022Q4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-10-23 | 2022Q4 | 2022Q4 | 2022Q4 | 2022Q4...</td>\n",
       "      <td>[-0.022726742550730705, 0.037290364503860474, ...</td>\n",
       "      <td>2022Q4 | 2022Q4 | 2022Q4 | 2022Q4 | 2022Q4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>2024-12-11 | 2024Q4 | RPLH eval + paper algori...</td>\n",
       "      <td>[-0.07699394971132278, 0.07493709772825241, -0...</td>\n",
       "      <td>2024Q4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>2024-12-12 | 2024Q4 | track-mjx meeting, RPLH ...</td>\n",
       "      <td>[-0.028125612065196037, 0.027043156325817108, ...</td>\n",
       "      <td>2024Q4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>2024-12-13 | 2024Q4 | constraint article, EM a...</td>\n",
       "      <td>[-0.08803687244653702, 0.03149242326617241, -0...</td>\n",
       "      <td>2024Q4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>2024-12-14 | 2024Q4 | chill</td>\n",
       "      <td>[-0.06347204744815826, 0.03524710237979889, 0....</td>\n",
       "      <td>2024Q4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>2024-12-15 | 2024Q4 | training, rplh summary</td>\n",
       "      <td>[-0.04076126217842102, 0.03703541308641434, -0...</td>\n",
       "      <td>2024Q4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>633 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 chunk  \\\n",
       "0    2022-02-14 | 2022Q1 | Book read (30m), DOC 2 P...   \n",
       "1    2022-02-15 | 2022Q1 | Nutrition read (15m), Ph...   \n",
       "2                       2022-10-21 | 2022Q4 | 2022Q4 |   \n",
       "3    2022-10-22 | 2022Q4 | 2022Q4 | After consecuti...   \n",
       "4    2022-10-23 | 2022Q4 | 2022Q4 | 2022Q4 | 2022Q4...   \n",
       "..                                                 ...   \n",
       "628  2024-12-11 | 2024Q4 | RPLH eval + paper algori...   \n",
       "629  2024-12-12 | 2024Q4 | track-mjx meeting, RPLH ...   \n",
       "630  2024-12-13 | 2024Q4 | constraint article, EM a...   \n",
       "631                        2024-12-14 | 2024Q4 | chill   \n",
       "632       2024-12-15 | 2024Q4 | training, rplh summary   \n",
       "\n",
       "                                             embedding  \\\n",
       "0    [-0.03888290748000145, 0.00010052329889731482,...   \n",
       "1    [-0.07007762789726257, -0.05126873403787613, 0...   \n",
       "2    [-0.04180379584431648, 0.03743821382522583, 0....   \n",
       "3    [-0.06285377591848373, -0.010527550242841244, ...   \n",
       "4    [-0.022726742550730705, 0.037290364503860474, ...   \n",
       "..                                                 ...   \n",
       "628  [-0.07699394971132278, 0.07493709772825241, -0...   \n",
       "629  [-0.028125612065196037, 0.027043156325817108, ...   \n",
       "630  [-0.08803687244653702, 0.03149242326617241, -0...   \n",
       "631  [-0.06347204744815826, 0.03524710237979889, 0....   \n",
       "632  [-0.04076126217842102, 0.03703541308641434, -0...   \n",
       "\n",
       "                                        quarter  \n",
       "0                                        2022Q1  \n",
       "1                                        2022Q1  \n",
       "2                               2022Q4 | 2022Q4  \n",
       "3                               2022Q4 | 2022Q4  \n",
       "4    2022Q4 | 2022Q4 | 2022Q4 | 2022Q4 | 2022Q4  \n",
       "..                                          ...  \n",
       "628                                      2024Q4  \n",
       "629                                      2024Q4  \n",
       "630                                      2024Q4  \n",
       "631                                      2024Q4  \n",
       "632                                      2024Q4  \n",
       "\n",
       "[633 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"...\" #os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"What did I mainly do in 2022 fall quarter?\"\n",
    "similar_chunks = get_similar_chunks(user_prompt, index, embedding_df, top_k=5)\n",
    "generate_response(user_prompt, similar_chunks, api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In 2023 fall quarter, I mainly did housework, planning, and training during the holiday break. I also spent time analyzing my spending and documenting it for Bank of America's 2022 fall quarter. I had a break on Christmas and New Year's Day. I also worked on various projects and submitted them, including a personal study time analysis project, a Cogs 9 final project, a DOC 1 portfolio, and a 大局观 for Math 18. I also had the opportunity to meet fun people during this time.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt = \"What did I mainly do in 2023 fall quarter?\"\n",
    "similar_chunks = get_similar_chunks(user_prompt, index, embedding_df, top_k=5)\n",
    "generate_response(user_prompt, similar_chunks, api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In 2024 fall quarter, you spent time cleaning your house, updating your resume and website, and analyzing study time data. You also spent time running and training your legs, and enjoyed some leisure activities. Additionally, you spent time working on a project for your Github repository.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt = \"What did I mainly do in 2024 fall quarter?\"\n",
    "similar_chunks = get_similar_chunks(user_prompt, index, embedding_df, top_k=5)\n",
    "generate_response(user_prompt, similar_chunks, api_key=api_key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc80",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
