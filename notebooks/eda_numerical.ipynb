{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorative Data Analysis\n",
    "For Visualization of the Dataset and some initial transfromation neccessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "current_folder = Path.cwd()\n",
    "parent_folder = current_folder.parent\n",
    "sys.path.insert(0, str(parent_folder))\n",
    "print(parent_folder)\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.keys()\n",
    "pio.renderers.default = 'notebook' \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import glob\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "from utils.clean_numerical import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data & Cleaning Them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_folder = Path.cwd()\n",
    "parent_folder = current_folder.parent\n",
    "os.chdir(parent_folder)\n",
    "print(parent_folder)\n",
    "\n",
    "# study time\n",
    "fall_2022 = pd.read_csv('data/2022_fall_study.csv')\n",
    "winter_2023 = pd.read_csv('data/2023_winter_study.csv')\n",
    "spring_2023 = pd.read_csv('data/2023_spring_study.csv')\n",
    "summer_2023 = pd.read_csv('data/2023_summer_study.csv')\n",
    "fall_2023 = pd.read_csv('data/2023_fall_study.csv')\n",
    "winter_2024 = pd.read_csv('data/2024_winter_study.csv')\n",
    "spring_2024 = pd.read_csv('data/2024_spring_study.csv')\n",
    "summer_2024 = pd.read_csv('data/2024_summer_study.csv')\n",
    "fall_2024 = pd.read_csv('data/2024_fall_study.csv')\n",
    "study = pd.concat([fall_2022, winter_2023, spring_2023, summer_2023, fall_2023, winter_2024, spring_2024, summer_2024, fall_2024], axis=0)\n",
    "\n",
    "# data_dir = 'data'\n",
    "# file_pattern = os.path.join(data_dir, '*_study.csv')\n",
    "# csv_files = glob.glob(file_pattern)\n",
    "# csv_files.sort()\n",
    "# df_list = [pd.read_csv(file) for file in csv_files]\n",
    "# study = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "# print(f\"Total records: {study.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_study = study.pipe(transform_study)\n",
    "clean_study.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_study.drop(columns=['total','exam','week'])\n",
    "\n",
    "# selecting 77 entries from the start of non-zero values for each column\n",
    "relevant_data = pd.DataFrame(index=range(77))\n",
    "\n",
    "for column in df.columns:\n",
    "    if df[column].dtype in [np.float64, np.int64]:  # Only apply to numeric columns\n",
    "        start_index = df[column].ne(0).idxmax()  # Find first non-zero index\n",
    "        # Check if there are at least 77 entries to slice, if not, adjust the range\n",
    "        end_index = min(start_index + 77, len(df))\n",
    "        relevant_data[column] = df[column][start_index:end_index].reset_index(drop=True)\n",
    "\n",
    "# median, mean, max, min, and standard deviation\n",
    "statistics = {}\n",
    "for column in relevant_data.columns:\n",
    "    if relevant_data[column].dtype in [np.float64, np.int64]:  # Apply only to numeric columns\n",
    "        statistics[column] = {\n",
    "            'Mean': relevant_data[column].mean(),\n",
    "            'Max': relevant_data[column].max(),\n",
    "            'Standard Deviation': relevant_data[column].std()\n",
    "        }\n",
    "\n",
    "stats_df = pd.DataFrame(statistics).T\n",
    "stats_df = stats_df.sort_index()\n",
    "stats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General EDA & Plotting Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map colors to the statistics DataFrame\n",
    "stats_df['Color'] = [GROUP_COLOR_MAP.get(COL_GROUP.get(col), 'gray') for col in stats_df.index]\n",
    "stats_df = stats_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by Color\n",
    "stats_df.sort_values(by=['Color', 'index'], inplace=True, ascending=False)\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=3, cols=1,\n",
    "    subplot_titles=(\"Maximum Study Time Per Day\",\"Mean Study Time Per Day\",\"Standard Deviation Study Time Per Day\"),\n",
    "    vertical_spacing=0.02  # Adjust spacing to your preference\n",
    ")\n",
    "\n",
    "unique_colors = stats_df['Color'].unique()\n",
    "color_labels = {color: group for group, color in GROUP_COLOR_MAP.items()}\n",
    "\n",
    "# Plotting each statistic with a trace for each color\n",
    "for i, stat in enumerate(['Max', 'Mean', 'Standard Deviation']):\n",
    "    for color in unique_colors:\n",
    "        filtered_df = stats_df[stats_df['Color'] == color]\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=filtered_df[stat],\n",
    "                y=filtered_df['index'],\n",
    "                orientation='h',\n",
    "                marker_color=color,\n",
    "                name=color_labels[color],\n",
    "                showlegend=(i == 0)  # Show legend only in the first subplot to avoid duplicates\n",
    "            ),\n",
    "            row=i+1, col=1\n",
    "        )\n",
    "\n",
    "# Update layout for clear visualization\n",
    "fig.update_layout(height=4000, width=1000, showlegend=True, title_text=\"Statistical Measures For Each Class's Study Time\")\n",
    "fig.update_xaxes(showgrid=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.violin(clean_study, y='total', title='Total Study Time Distribution')\n",
    "fig.update_layout(showlegend=True, xaxis_title='Distributionr', yaxis_title='Totao Study Time Per Day')\n",
    "fig.update_xaxes(showgrid=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "\n",
    "clean_study['year'] = clean_study['date'].dt.year\n",
    "clean_study['season'] = clean_study['date'].dt.quarter\n",
    "clean_study['month'] = clean_study['date'].dt.month\n",
    "clean_study['weekday'] = clean_study['date'].dt.weekday\n",
    "clean_study['week_number'] =  clean_study['date'].dt.isocalendar().week\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trends in Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(clean_study, x='date',y='total',trendline='lowess')\n",
    "fig.update_layout(showlegend=True, title_text=\"Total Study Time Progression\", xaxis_title='date', yaxis_title='Totao Study Time Per Day')\n",
    "fig.update_xaxes(showgrid=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = clean_study\n",
    "dsc_cols = [col for col in df.columns if 'ds' in col]\n",
    "math_cols = [col for col in df.columns if 'math' in col]\n",
    "research_cols = [col for col in df.columns if ('salk' in col) |\n",
    "                 ('cse150b' in col) | ('fmp' in col) | ('cl' in col) | ('cse257' in col) | \n",
    "                 ('dsc190' in col) | ('sof' in col) | ('track-mjx' in col)]\n",
    "cogs_cols = [col for col in df.columns if 'cogs' in col]\n",
    "\n",
    "df['dsc_total'] = df[dsc_cols].sum(axis=1)\n",
    "df['math_total'] = df[math_cols].sum(axis=1)\n",
    "df['salk_total'] = df[research_cols].sum(axis=1)\n",
    "df['cogs_total'] = df[cogs_cols].sum(axis=1)\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "# Scatter plots\n",
    "plt.scatter(df['date'], df['dsc_total'], label='DSC Total', color='blue')\n",
    "plt.scatter(df['date'], df['math_total'], label='Math Total', color='green')\n",
    "plt.scatter(df['date'], df['salk_total'], label='Research Total', color='red')\n",
    "plt.scatter(df['date'], df['cogs_total'], label='COGS Total', color='orange')  # New scatter plot for COGS\n",
    "\n",
    "# Trend lines (linear regression)\n",
    "df['date_num'] = pd.to_numeric(pd.to_datetime(df['date']))\n",
    "\n",
    "# DSC trend line\n",
    "z_dsc = np.polyfit(df['date_num'], df['dsc_total'], 1)\n",
    "p_dsc = np.poly1d(z_dsc)\n",
    "plt.plot(df['date'], p_dsc(df['date_num']), color='blue', linestyle='dashed', linewidth=5)  # Thicker line\n",
    "\n",
    "# Math trend line\n",
    "z_math = np.polyfit(df['date_num'], df['math_total'], 1)\n",
    "p_math = np.poly1d(z_math)\n",
    "plt.plot(df['date'], p_math(df['date_num']), color='green', linestyle='dashed', linewidth=5)\n",
    "\n",
    "# Research trend line\n",
    "z_salk = np.polyfit(df['date_num'], df['salk_total'], 1)\n",
    "p_salk = np.poly1d(z_salk)\n",
    "plt.plot(df['date'], p_salk(df['date_num']), color='red', linestyle='dashed', linewidth=5)\n",
    "\n",
    "# COGS trend line\n",
    "z_cogs = np.polyfit(df['date_num'], df['cogs_total'], 1)\n",
    "p_cogs = np.poly1d(z_cogs)\n",
    "plt.plot(df['date'], p_cogs(df['date_num']), color='orange', linestyle='dashed', linewidth=5)\n",
    "\n",
    "plt.xlabel('Dates')\n",
    "plt.ylabel('Total Time Spent')\n",
    "plt.title('Scatter with Trend Lines: Changes across time for DSC, Math, Research, and COGS')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = clean_study.assign(week_of_year = clean_study['date'].dt.weekofyear)\n",
    "group_by_week = grouped.groupby('week_of_year').max().reset_index()\n",
    "fig = px.scatter(group_by_week, x='week_of_year',y='total',trendline='lowess')\n",
    "fig.update_layout(showlegend=True, title_text=\"'Max of Single Day Study Time Over Time'\", xaxis_title='Week of Year', yaxis_title='Totao Study Time Per Day')\n",
    "fig.update_xaxes(showgrid=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_total = clean_study.groupby('year')['total'].sum().reset_index()\n",
    "sns.barplot(data=yearly_total, x='year', y='total')\n",
    "plt.title('Total Study Hours per Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trends in Seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = {1: 'Winter', 2: 'Spring', 3: 'Summer', 4: 'Fall'}\n",
    "clean_study['season_name'] = clean_study['season'].map(seasons)\n",
    "seasonal_total = clean_study.groupby('season_name')['total'].sum().reset_index()\n",
    "sns.barplot(data=seasonal_total, x='season_name', y='total')\n",
    "plt.title('Total Study Hours per Season')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table = clean_study.pivot_table(index='year', columns='season_name', values='total', aggfunc='sum')\n",
    "sns.heatmap(pivot_table, cmap='YlGnBu')\n",
    "plt.title('Heatmap of Total Study Hours Over Time by Season')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap of Study Hours By Weekday Compare to Week Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_avg = clean_study.groupby('weekday')['total'].mean().reset_index()\n",
    "weekday_avg['weekday_name'] = weekday_avg['weekday'].apply(lambda x: calendar.day_name[x])\n",
    "\n",
    "sns.barplot(data=weekday_avg, x='weekday_name', y='total')\n",
    "plt.title('Average Total Study Hours by Weekday')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_weekday = clean_study.pivot_table(index='week_number', columns='weekday', values='total', aggfunc='sum')\n",
    "\n",
    "sns.heatmap(pivot_weekday, cmap='viridis')\n",
    "plt.title('Heatmap of Total Study Hours by Week and Weekday')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_yearly_heatmaps(df, years, cols=3, cmap='viridis'):\n",
    "    '''Plot heatmap per year'''\n",
    "    \n",
    "    num_years = len(years)\n",
    "    rows = int(num_years / cols)\n",
    "    \n",
    "    plt.figure(figsize=(cols * 6, rows * 5))\n",
    "    \n",
    "    for idx, year in enumerate(years):\n",
    "        plt.subplot(rows, cols, idx + 1)\n",
    "        \n",
    "        df_year = df[df['year'] == year]\n",
    "        \n",
    "        # pivot table: index=week_number, columns=weekday, values=total\n",
    "        pivot_weekday = df_year.pivot_table(\n",
    "            index='week_number',\n",
    "            columns='weekday',\n",
    "            values='total',\n",
    "            aggfunc='sum'\n",
    "        )\n",
    "        \n",
    "        # map numerical weekdays to names\n",
    "        pivot_weekday.columns = [calendar.day_name[int(day)] for day in pivot_weekday.columns]\n",
    "        \n",
    "        # make sure that weekdays are ordered correctly\n",
    "        ordered_weekdays = list(calendar.day_name)\n",
    "        pivot_weekday = pivot_weekday.reindex(columns=ordered_weekdays)\n",
    "        \n",
    "        sns.heatmap(pivot_weekday, cmap=cmap, linewidths=.5, linecolor='gray', cbar=True)\n",
    "        \n",
    "        plt.title(f'Total Study Hours in {year}', fontsize=14)\n",
    "        plt.xlabel('Weekday', fontsize=12)\n",
    "        plt.ylabel('Week Number', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "years = sorted(clean_study['year'].unique())\n",
    "plot_yearly_heatmaps(clean_study, years, cols=3, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Window of 30 Days Trend Over the Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_total = clean_study.groupby(['year', 'month'])['total'].sum().reset_index()\n",
    "monthly_total['month_name'] = monthly_total['month'].apply(lambda x: calendar.month_name[x])\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.lineplot(data=monthly_total, x='month', y='total', hue='year', marker='o')\n",
    "plt.title('Monthly Total Study Hours Over Years')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Total Study Hours')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Exam's Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_periods = [\n",
    "    ('2023-12-01', '2023-12-15'),\n",
    "    ('2024-05-01', '2024-05-15'),\n",
    "    \n",
    "]\n",
    "\n",
    "study['is_exam_period'] = False\n",
    "for start, end in exam_periods:\n",
    "    study.loc[(study['date'] >= start) & (study['date'] <= end), 'is_exam_period'] = True\n",
    "\n",
    "# Compare study hours during exam periods\n",
    "sns.boxplot(data=study, x='is_exam_period', y='total')\n",
    "plt.title('Total Study Hours During Exam Periods vs. Others')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction\n",
    "\n",
    "| **Technique**       | **Type**      | **Supervised** | **Preserves Local Structure** | **Preserves Global Structure** | **Best For**                                      |\n",
    "|:--------------------|:-------------:|:---------------:|:------------------------------:|:--------------------------------:|:-------------------------------------------------|\n",
    "| **PCA**             | Linear        | No              | Moderate                      | High                             | Data compression, noise reduction                |\n",
    "| **t-SNE**           | Non-Linear    | No              | High                          | Low                              | Visualization of clusters                        |\n",
    "| **UMAP**            | Non-Linear    | No              | High                          | Moderate to High                 | Visualization, preserving more structure         |\n",
    "| **LDA**             | Linear        | Yes             | Moderate                      | High                             | Classification, maximizing class separation      |\n",
    "| **Factor Analysis** | Linear        | No              | Low                           | Moderate                         | Identifying latent factors                       |\n",
    "| **NMF**             | Linear        | No              | Moderate                      | Low                              | Parts-based representation, interpretability      |\n",
    "| **ICA**             | Linear        | No              | High                          | Low                              | Signal separation, feature extraction            |\n",
    "| **Autoencoders**    | Non-Linear    | No              | High                          | High                             | Complex data representations, anomaly detection   |\n",
    "| **Kernel PCA**      | Non-Linear    | No              | Moderate to High              | Moderate                         | Non-linear data structures                       |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "numerical_cols = clean_study.select_dtypes(include=['number']).columns.tolist()\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(clean_study[numerical_cols])\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(scaled_data)\n",
    "clean_study['PC1'] = principal_components[:, 0]\n",
    "clean_study['PC2'] = principal_components[:, 1]\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.scatterplot(data=clean_study, x='PC1', y='PC2', hue='season_name')\n",
    "plt.title('PCA of Study Data')\n",
    "plt.show()\n",
    "\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "principal_components = pca.fit_transform(scaled_data)\n",
    "\n",
    "clean_study['PC1'] = principal_components[:, 0]\n",
    "clean_study['PC2'] = principal_components[:, 1]\n",
    "clean_study['PC3'] = principal_components[:, 2]\n",
    "\n",
    "print(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)\n",
    "print(\"Total Explained Variance:\", sum(pca.explained_variance_ratio_))\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "scatter = ax.scatter(\n",
    "    clean_study['PC1'],\n",
    "    clean_study['PC2'],\n",
    "    clean_study['PC3'],\n",
    "    c=clean_study['season_name'].astype('category').cat.codes,  # Convert categories to numeric codes for coloring\n",
    "    cmap='viridis',\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.2f}%)')\n",
    "ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.2f}%)')\n",
    "ax.set_zlabel(f'PC3 ({pca.explained_variance_ratio_[2]*100:.2f}%)')\n",
    "ax.set_title('3D PCA of Study Data')\n",
    "\n",
    "legend1 = ax.legend(*scatter.legend_elements(),\n",
    "                    title=\"Seasons\", loc=\"upper right\", bbox_to_anchor=(1.15, 1))\n",
    "ax.add_artist(legend1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "kpca = KernelPCA(n_components=2, kernel='rbf', gamma=0.04, random_state=42)\n",
    "kpca_results = kpca.fit_transform(scaled_data)\n",
    "\n",
    "clean_study['kPCA1'] = kpca_results[:, 0]\n",
    "clean_study['kPCA2'] = kpca_results[:, 1]\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.scatterplot(\n",
    "    x='kPCA1', y='kPCA2',\n",
    "    hue='season_name',\n",
    "    data=clean_study,\n",
    "    legend='full',\n",
    "    alpha=0.7\n",
    ")\n",
    "plt.title('Kernel PCA of Study Data')\n",
    "plt.xlabel('kPCA Component 1')\n",
    "plt.ylabel('kPCA Component 2')\n",
    "plt.legend(title='Season')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpca = KernelPCA(n_components=3, kernel='rbf', gamma=0.04, random_state=42)\n",
    "kpca_results = kpca.fit_transform(scaled_data)\n",
    "\n",
    "clean_study['kPCA1'] = kpca_results[:, 0]\n",
    "clean_study['kPCA2'] = kpca_results[:, 1]\n",
    "clean_study['kPCA3'] = kpca_results[:, 2]\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "scatter = ax.scatter(\n",
    "    clean_study['kPCA1'],\n",
    "    clean_study['kPCA2'],\n",
    "    clean_study['kPCA3'],\n",
    "    c=clean_study['season_name'].astype('category').cat.codes,  # Convert categories to numeric codes for coloring\n",
    "    cmap='viridis',\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "ax.set_xlabel(f'kPC1 ({pca.explained_variance_ratio_[0]*100:.2f}%)')\n",
    "ax.set_ylabel(f'kPC2 ({pca.explained_variance_ratio_[1]*100:.2f}%)')\n",
    "ax.set_zlabel(f'kPC3 ({pca.explained_variance_ratio_[2]*100:.2f}%)')\n",
    "ax.set_title('3D Kernel PCA of Study Data')\n",
    "\n",
    "legend1 = ax.legend(*scatter.legend_elements(),\n",
    "                    title=\"Seasons\", loc=\"upper right\", bbox_to_anchor=(1.15, 1))\n",
    "ax.add_artist(legend1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)\n",
    "tsne_results = tsne.fit_transform(scaled_data)\n",
    "\n",
    "clean_study['tSNE1'] = tsne_results[:, 0]\n",
    "clean_study['tSNE2'] = tsne_results[:, 1]\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.scatterplot(\n",
    "    x='tSNE1', y='tSNE2',\n",
    "    hue='season_name',\n",
    "    data=clean_study,\n",
    "    legend='full',\n",
    "    alpha=0.7\n",
    ")\n",
    "plt.title('t-SNE of Study Data')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.legend(title='Season')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=3, random_state=42, perplexity=30, n_iter=1000)\n",
    "tsne_results = tsne.fit_transform(scaled_data)\n",
    "\n",
    "clean_study['tSNE1'] = tsne_results[:, 0]\n",
    "clean_study['tSNE2'] = tsne_results[:, 1]\n",
    "clean_study['tSNE3'] = tsne_results[:, 2]\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "scatter = ax.scatter(\n",
    "    clean_study['tSNE1'],\n",
    "    clean_study['tSNE2'],\n",
    "    clean_study['tSNE3'],\n",
    "    c=clean_study['season_name'].astype('category').cat.codes,  # Convert categories to numeric codes for coloring\n",
    "    cmap='viridis',\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "ax.set_xlabel(f'tSNE1 ({pca.explained_variance_ratio_[0]*100:.2f}%)')\n",
    "ax.set_ylabel(f'tSNE2 ({pca.explained_variance_ratio_[1]*100:.2f}%)')\n",
    "ax.set_zlabel(f'tSNE3 ({pca.explained_variance_ratio_[2]*100:.2f}%)')\n",
    "ax.set_title('3D T-SNE of Study Data')\n",
    "\n",
    "legend1 = ax.legend(*scatter.legend_elements(),\n",
    "                    title=\"Seasons\", loc=\"upper right\", bbox_to_anchor=(1.15, 1))\n",
    "ax.add_artist(legend1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "umap_reducer = umap.UMAP(n_components=2, random_state=42, n_neighbors=15, min_dist=0.1)\n",
    "umap_results = umap_reducer.fit_transform(scaled_data)\n",
    "\n",
    "clean_study['UMAP1'] = umap_results[:, 0]\n",
    "clean_study['UMAP2'] = umap_results[:, 1]\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.scatterplot(\n",
    "    x='UMAP1', y='UMAP2',\n",
    "    hue='season_name',\n",
    "    data=clean_study,\n",
    "    legend='full',\n",
    "    alpha=0.7\n",
    ")\n",
    "plt.title('UMAP of Study Data')\n",
    "plt.xlabel('UMAP Component 1')\n",
    "plt.ylabel('UMAP Component 2')\n",
    "plt.legend(title='Season')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc80",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
